@techreport{ulicny2023combining,
       doi={10.48550/arXiv.2305.08232},
	   url={https://arxiv.org/pdf/2305.08232.pdf},
	   abstract={We propose a pipeline for combined multi-class object geolocation and height estimation from street level RGB imagery, which is considered as a single available input data modality. Our solution is formulated via Markov Random Field optimization with deterministic output. The proposed technique uses image metadata along with coordinates of objects detected in the image plane as found by a custom-trained Convolutional Neural Network. Computing the object height using our methodology, in addition to object geolocation, has negligible effect on the overall computational cost. Accuracy is demonstrated experimentally for water drains and road signs on which we achieve average elevation estimation error lower than 20cm.},
      title={Combining geolocation and height estimation of objects from street level imagery}, 
      author={Matej Ulicny and Vladimir A. Krylov and Julie Connelly and Rozenn Dahyot},
      year={2023},
      eprint={2305.08232},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@techreport{Chopin2023,
  doi = {10.48550/ARXIV.2301.07468},
  
  url = {https://arxiv.org/pdf/2301.07468.pdf},
  
  abstract={Deep learning based pipelines for semantic segmentation often ignore structural information available on annotated images used for training. We propose a novel post-processing module enforcing structural knowledge about the objects of interest to improve segmentation results provided by deep learning. This module corresponds to a "many-to-one-or-none" inexact graph matching approach, and is formulated as a quadratic assignment problem. Our approach is compared to a CNN-based segmentation (for various CNN backbones) on two public datasets, one for face segmentation from 2D RGB images (FASSEG), and the other for brain segmentation from 3D MRIs (IBSR). Evaluations are performed using two types of structural information (distances and directional relations, , this choice being a hyper-parameter of our generic framework). On FASSEG data, results show that our module improves accuracy of the CNN by about 6.3% (the Hausdorff distance decreases from 22.11 to 20.71). On IBSR data, the improvement is of 51% (the Hausdorff distance decreases from 11.01 to 5.4). In addition, our approach is shown to be resilient to small training datasets that often limit the performance of deep learning methods: the improvement increases as the size of the training dataset decreases.},
  
  author = {Chopin, Jérémy and Fasquel, Jean-Baptiste and Mouchère, Harold and Dahyot, Rozenn and Bloch, Isabelle},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences, I.4.5},
  
  title = {Model-based inexact graph matching on top of CNNs for semantic scene understanding},
  
  publisher = {arXiv},
  
  year = {2023},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@techreport{Dahyot_PCC2022,
 
  author = {Dahyot, Rozenn},
  
  keywords = {Supervised Learning, PCA, classification, metric learning, deep learning, class encoding},
  abstract={We propose to directly compute classification estimates
by learning features encoded with their class scores. 
Our resulting model has a encoder-decoder structure suitable for supervised learning, it is computationally efficient and performs well for classification on several datasets.},

  title = {Principal Component Classification},
  
  publisher = {arXiv},
  
  year = {2022},
   doi = {10.48550/ARXIV.2210.12746},
  
  url = {https://arxiv.org/pdf/2210.12746.pdf},
  
  copyright = {Creative Commons Attribution 4.0 International},
}

@INPROCEEDINGS{KoteySLT2023,
  author={Kotey, Samantha and Dahyot, Rozenn and Harte, Naomi},
  booktitle={2022 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Fine Grained Spoken Document Summarization Through Text Segmentation}, 
  year={2023},
  volume={},
  number={},
  pages={647-654},
  abstract={Podcast transcripts are long spoken documents of conversational dialogue. Challenging to summarize, podcasts cover a diverse range of topics, vary in length, and have uniquely different linguistic styles. Previous studies in podcast summarization have generated short, concise dialogue summaries. In contrast, we propose a method to generate long fine-grained summaries, which describe details of sub-topic narratives. Leveraging a readability formula, we curate a data subset to train a long sequence transformer for abstractive summarization. Through text segmentation, we filter the evaluation data and exclude specific segments of text. We apply the model to segmented data, producing different types of fine grained summaries. We show that appropriate filtering creates comparable results on ROUGE and serves as an alternative method to truncation. Experiments show our model outperforms previous studies on the Spotify podcast dataset when tasked with generating longer sequences of text.},
  keywords={},
  doi={10.1109/SLT54892.2023.10022829},
  url={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10022829},
  ISSN={},
  month={Jan},}


@article{ULICNY2022108707, 
author= {Matej Ulicny and Vladimir A. Krylov and Rozenn Dahyot}, 
title= {Harmonic Convolutional Networks based on Discrete Cosine Transform}, 
journal={Pattern Recognition},
abstract={Convolutional neural networks (CNNs) learn filters in order to capture local correlation patterns in feature space. We propose to learn these filters as combinations of preset spectral filters defined by the Discrete Cosine Transform (DCT). Our proposed DCT-based harmonic blocks replace conventional convolutional layers to produce partially or fully harmonic versions of new or existing CNN architectures. Using DCT energy compaction properties, we demonstrate how the harmonic networks can be efficiently compressed by truncating high-frequency information in harmonic blocks thanks to the redundancies in the spectral domain. We report extensive experimental validation demonstrating benefits of the introduction of harmonic blocks into state-of-the-art CNN models in image classification, object detection and semantic segmentation applications.},
volume= {129},
pages={1-12},
year= {2022}, 
issn = {0031-3203},
url= {https://arxiv.org/pdf/2001.06570.pdf},
doi={10.1016/j.patcog.2022.108707},
note={arXiv.2001.06570  Github: https://github.com/matej-ulicny/harmonic-networks},
}
,
@inproceedings{ChopinICPRAI2022a,
title={Improving semantic segmentation with graph-based structural knowledge},
author={J. Chopin and J.-B. Fasquel and H. Mouchere and R. Dahyot and I. Bloch},
abstract={Deep learning based pipelines for semantic segmentation often
ignore structural information available on annotated images used for
training. We propose a novel post-processing module enforcing structural
knowledge about the objects of interest to improve segmentation
results provided by deep learning. This module corresponds to a “manyto-
one-or-none” inexact graph matching approach, and is formulated as
a quadratic assignment problem. Using two standard measures for evaluation,
we show experimentally that our pipeline for segmentation of
3D MRI data of the brain outperforms the baseline CNN (U-Net) used
alone. In addition, our approach is shown to be resilient to small training
datasets that often limit the performance of deep learning.},
doi={10.1007/978-3-031-09037-0_15},
url= {https://hal.inria.fr/hal-03633029}, 
note={hal-03633029},
booktitle={Pattern Recognition and Artificial Intelligence},
year={2022},
publisher={Springer International Publishing},
editor={El Yacoubi, Moun{\^i}m
and Granger, Eric
and Yuen, Pong Chi
and Pal, Umapada
and Vincent, Nicole},
month={June},
HAL_ID = {hal-03633029},
address={Paris, France},
isbn={978-3-031-09037-0},
pages={173--184},
},




@inproceedings{ChopinICPRAI2022b,
title={QAP Optimisation with Reinforcement Learning for Faster Graph Matching in Sequential Semantic Image Analysis},
author={J. Chopin and J.-B. Fasquel and H. Mouchere and R. Dahyot and I. Bloch},
abstract={The paper addresses the fundamental task of semantic image
analysis by exploiting structural information (spatial relationships
between image regions). We propose to perform such semantic image
analysis by combining a deep neural network (CNN) with graph matching
where graphs encode efficiently structural information related to regions
segmented by the CNN. Our novel approach solves the quadratic assignment
problem (QAP) sequentially for matching graphs. The optimal
sequence for graph matching is conveniently defined using reinforcementlearning
(RL) based on the region membership probabilities produced by
the CNN and their structural relationships. Our RL based strategy for
solving QAP sequentially allows us to significantly reduce the combinatioral
complexity for graph matching. Preliminary experiments are performed
on both a synthetic dataset and a public dataset dedicated to the
semantic segmentation of face images. Results show that the proposed
RL-based ordering dramatically outperforms random ordering, and that
our strategy is about 386 times faster than a global QAP-based approach,
while preserving similar segmentation accuracy.},
publisher={Springer International Publishing},
editor={El Yacoubi, Moun{\^i}m
and Granger, Eric
and Yuen, Pong Chi
and Pal, Umapada
and Vincent, Nicole},
isbn={978-3-031-09037-0},
doi={10.1007/978-3-031-09037-0_5},
url= {https://hal.inria.fr/hal-03633036/}, 
note={hal-03633036},
booktitle={Pattern Recognition and Artificial Intelligence},
year={2022},
month={June},
pages={47--58},
address={Paris, France},
},


@inproceedings{karaali2022drvnet,
      title={DR-VNet: Retinal Vessel Segmentation via Dense Residual UNet}, 
      author={Ali Karaali and Rozenn Dahyot and Donal J. Sexton},
      year={2022},
	  booktitle={Pattern Recognition and Artificial Intelligence},
	  doi={10.1007/978-3-031-09037-0_17},
	  note={Github https://github.com/alikaraali/DR-VNet, ArXivDOI:10.48550/arXiv.2111.04739},
	  url= {https://arxiv.org/pdf/2111.04739.pdf}, 
	  abstract={Accurate retinal vessel segmentation is an important task for many computer-aided diagnosis systems. Yet, it is still a challenging problem due to the complex vessel structures of an eye. Numerous vessel segmentation methods have been proposed recently, however more research is needed to deal with poor segmentation of thin and tiny vessels. To address this, we propose a new deep learning pipeline combining the efficiency of residual dense net blocks and, residual squeeze and excitation blocks. We validate experimentally our approach on three datasets and show that our pipeline outperforms current state of the art techniques on the sensitivity metric relevant to assess capture of small vessels.},
	  publisher={Springer International Publishing},
editor={El Yacoubi, Moun{\^i}m
and Granger, Eric
and Yuen, Pong Chi
and Pal, Umapada
and Vincent, Nicole},
isbn={978-3-031-09037-0},
      volume= {abs/2111.04739},
	  month={June},
address={Paris, France},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}
,




@inproceedings{ChaoImvip2021,
author= {C.-J. Liu and Matej Ulicny and Michael Manzke and  Rozenn Dahyot}, 
title= {Context Aware Object Geotagging},
booktitle= {Irish Machine Vision and Image Processing (IMVIP 2021)},
volume= {},
year= {2021},
abstract={We propose an approach for geolocating assets from street view imagery 
by improving the quality of the metadata associated with the images using 
Structure from Motion, and by using contextual geographic information extracted 
from OpenStreetMap. Our pipeline is validated experimentally against the state of
 the art approaches for geotagging traffic lights.},
url= {https://arxiv.org/pdf/2108.06302.pdf},
doi={10.48550/arXiv.2108.06302},
note={},
archivePrefix= {arXiv}, 
eprint= {},
timestamp= {},
biburl= {},
bibsource= {}
},

@article{McDonnell2021,
 title= {Model for predicting perception of facial action unit activation using virtual humans},
 journal= {Computers \& Graphics }, 
doi = {10.1016/j.cag.2021.07.022},
 volume= {100}, 
 pages= {81-92}, 
 year= {2021}, 
 note= {Winner 2022 Graphics Replicability Stamp Initiative (GRSI) best paper award; Github: https://github.com/Roznn/facial-blendshapes}, 
 issn= {0097-8493},
 url= {https://roznn.github.io/facial-blendshapes/CAG2021.pdf}, 
 author= {Rachel McDonnell and Katja Zibrek and Emma Carrigan and Rozenn Dahyot}, 
 keywords= {facial action unit, perception, virtual character},
 abstract= {Blendshape facial rigs are used extensively in the industry for facial animation of
virtual humans. However, storing and manipulating large numbers of facial meshes
(blendshapes) is costly in terms of memory and computation for gaming applications.
Blendshape rigs are comprised of sets of semantically-meaningful expressions, which
govern how expressive the character will be, often based on Action Units from the Facial
Action Coding System (FACS). However, the relative perceptual importance of blendshapes has not yet been investigated. Research in Psychology and Neuroscience has
shown that our brains process faces differently than other objects so we postulate that
the perception of facial expressions will be feature-dependent rather than based purely
on the amount of movement required to make the expression. Therefore, we believe that
perception of blendshape visibility will not be reliably predicted by numerical calculations of the difference between the expression and the neutral mesh. In this paper, we
explore the noticeability of blendshapes under different activation levels, and present
new perceptually-based models to predict perceptual importance of blendshapes. The
models predict visibility based on commonly-used geometry and image-based metrics.}
 },


@inproceedings{alghamdi2021sliced,
      title = {Sliced L2 Distance for Colour Grading}, 
      author = {Hana Alghamdi and Rozenn Dahyot},
	  booktitle = {2021 29th European Signal Processing Conference (EUSIPCO)},
	  doi = {10.23919/EUSIPCO54536.2021.9616260},
      year = {2021},
	  volume={},
      number={},
      pages={671-675},
      eprint = {2102.09297},
	  archivePrefix = {arXiv},
      primaryClass = {cs.CV},
	  abstract = {We propose a new method with L2 distance that maps one N-dimensional distribution to another,
	  taking into account available information about correspondences. We solve the high-dimensional problem 
	  in 1D space using an iterative projection approach. To show the potentials of this mapping, we apply it
	  to colour transfer between two images that exhibit overlapped scenes. Experiments show quantitative and 
	  qualitative competitive results as compared with the state of the art colour transfer methods.},
	  note={https://arxiv.org/pdf/2102.09297.pdf},
	  url = {https://eurasip.org/Proceedings/Eusipco/Eusipco2021/pdfs/0000671.pdf}
},

